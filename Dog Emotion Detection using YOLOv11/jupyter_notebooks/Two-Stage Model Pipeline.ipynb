{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a4442b-750f-4d46-b1df-7f46635c22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pyttsx3  # For voice feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0446b338-8d4c-467d-a797-fc22b54f06e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources released safely\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load models ONCE outside the loop (critical for stability)\n",
    "dog_detector = YOLO(\"yolov8m.pt\")\n",
    "behavior_model = YOLO(r\"C:\\Users\\Abhijeet Singh\\Downloads\\tensorflow\\data_augmented1\\Data\\runs\\detect\\train\\weights\\best.pt\")\n",
    "\n",
    "# Define your behavior classes (MODIFY ACCORDING TO YOUR MODEL)\n",
    "behavior_classes = ['relax' , 'happy' , 'angry' , 'frown' , 'alert'] \n",
    "\n",
    "# Webcam setup with error checking\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)  # HD width\n",
    "cap.set(4, 720)   # HD height\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam. Check camera permissions/connections.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. Safely read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Frame capture error, restarting...\")\n",
    "            cap.release()\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            continue\n",
    "\n",
    "        # 2. Convert frame for YOLO (BGR to RGB)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 3. Stage 1: Dog detection\n",
    "        dog_results = dog_detector(rgb_frame, classes=[16], conf=0.4, iou=0.5, verbose=False)\n",
    "        \n",
    "        # 4. Process detections\n",
    "        for box in dog_results[0].boxes.xyxy.cpu().numpy():\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Ensure valid ROI coordinates\n",
    "            if x1 < x2 and y1 < y2 and all(v >= 0 for v in [x1, y1, x2, y2]):\n",
    "                try:\n",
    "                    # 5. Stage 2: Behavior analysis\n",
    "                    dog_roi = rgb_frame[y1:y2, x1:x2]\n",
    "                    if dog_roi.size == 0:  # Skip empty ROIs\n",
    "                        continue\n",
    "                        \n",
    "                    behavior_results = behavior_model(dog_roi, verbose=False)\n",
    "                    \n",
    "                    # Get behavior label (adapt based on your model type)\n",
    "                    if behavior_results[0].probs:  # Classification model\n",
    "                        label = behavior_results[0].probs.top1\n",
    "                    else:  # Detection model\n",
    "                        label = int(behavior_results[0].boxes.cls[0])\n",
    "                    \n",
    "                    behavior = behavior_classes[label]\n",
    "                    \n",
    "                    # Draw results\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, behavior, (x1, y1-10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "                except Exception as e:\n",
    "                    print(f\"ROI processing error: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        # 6. Display output\n",
    "        cv2.imshow('Dog Behavior Monitor', frame)\n",
    "        \n",
    "        # 7. Exit condition\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Critical error: {str(e)}\")\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Ensure clean resource release\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Resources released safely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99efcf3e-2927-43f2-ab00-48b0bcdb7ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources released safely.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import traceback\n",
    "from ultralytics import YOLO  # Assuming you're using Ultralytics YOLOv8\n",
    "\n",
    "# Load models once\n",
    "dog_detector = YOLO(\"yolov8m.pt\")\n",
    "behavior_model = YOLO(r\"C:\\Users\\Abhijeet Singh\\Downloads\\tensorflow\\data_augmented1\\Data\\runs\\detect\\train\\weights\\best.pt\")\n",
    "\n",
    "behavior_classes = ['relax', 'happy', 'angry', 'frown', 'alert']\n",
    "CONF_THRESHOLD = 0.5\n",
    "SMOOTHING_FRAMES = 11  # How many frames to consider for smoothing\n",
    "\n",
    "# Smoothing dictionary: maps dog_id -> deque of recent labels\n",
    "dog_label_history = defaultdict(lambda: deque(maxlen=SMOOTHING_FRAMES))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Frame capture error. Restarting camera.\")\n",
    "            cap.release()\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            continue\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Stage 1: Detect dogs\n",
    "        dog_results = dog_detector(rgb_frame, classes=[16], conf=0.4, iou=0.4, verbose=False)\n",
    "\n",
    "        for i, box in enumerate(dog_results[0].boxes.xyxy.cpu().numpy()):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "            if x1 < x2 and y1 < y2 and all(v >= 0 for v in [x1, y1, x2, y2]):\n",
    "                try:\n",
    "                    dog_roi = rgb_frame[y1:y2, x1:x2]\n",
    "                    if dog_roi.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    behavior_results = behavior_model(dog_roi, verbose=False)\n",
    "\n",
    "                    if behavior_results[0].probs:\n",
    "                        probs = behavior_results[0].probs.data.cpu().numpy()\n",
    "                        label_idx = int(np.argmax(probs))\n",
    "                        confidence = float(probs[label_idx])\n",
    "                    else:\n",
    "                        boxes = behavior_results[0].boxes\n",
    "                        if not boxes:\n",
    "                            continue\n",
    "                        label_idx = int(boxes.cls[0])\n",
    "                        confidence = float(boxes.conf[0])\n",
    "\n",
    "                    if confidence < CONF_THRESHOLD:\n",
    "                        continue\n",
    "\n",
    "                    # Smooth predictions using majority vote\n",
    "                    dog_id = f\"{x1}_{y1}_{x2}_{y2}\"\n",
    "                    dog_label_history[dog_id].append(label_idx)\n",
    "                    most_common_label = max(set(dog_label_history[dog_id]), key=dog_label_history[dog_id].count)\n",
    "                    behavior = behavior_classes[most_common_label]\n",
    "\n",
    "                    # Draw bounding box and label\n",
    "                    label_text = f\"{behavior} ({int(confidence * 100)}%)\"\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label_text, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in behavior detection: {e}\")\n",
    "                    continue\n",
    "\n",
    "        cv2.imshow(\"Dog Behavior Monitor\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Critical error: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Resources released safely.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch-gpu]",
   "language": "python",
   "name": "conda-env-.conda-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
